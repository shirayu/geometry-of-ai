# 第8回：時間の発見

## 問題 8-1 ★ 残差接続とNeural ODE

残差接続 $h' = h + f(h)$ を「オイラー法による微分方程式の離散化」と見なすとき、対応する微分方程式を書け。

**ヒント:** オイラー法： $y(t+\Delta t) \approx y(t) + \Delta t \cdot dy/dt$

**解答:**
残差接続を離散化と見ると：

- $h' = h + f(h)$
- これは $h(t+1) = h(t) + f(h(t))$ と同等
- ステップサイズ $\Delta t = 1$ のオイラー法

対応する微分方程式：
**$dh/dt = f(h, t)$**

**解釈:**

- 各層が「時刻」に対応
- $f(h)$ は「速度場」を定義
- ネットワークを通過する過程は、この速度場に沿った流れ

これがNeural ODEの基本的アイデア。連続時間極限を考えると、層の数を無限に増やしても安定に振る舞う可能性がある。

## 問題 8-2 ★★ 正規化と時間発展

「空間が安定すると、時間発展（プロセス）が扱えるようになる」という講義の主張を、BatchNorm/LayerNormの役割から説明せよ。

**ヒント:** 勾配の爆発・消失と、残差接続の効果を考えよ。

**解答:**
**正規化なしの問題:**

- 層を通過するごとに、活性化の分布がドリフトする（共変量シフト）
- ノルムが指数的に増大または減衰しうる
- 勾配も同様に爆発・消失
- → 深いネットワークの学習が不安定

**正規化ありの効果:**

- 各層の出力の分布を安定化（平均・分散を一定に保つ）
- ノルムの暴走を防ぐ
- → 勾配が安定して流れる

**残差接続との相乗効果:**

- 残差接続：情報を「スキップ」させて勾配消失を防ぐ
- 正規化：各層の出力を安定化
- 両者により、「層を増やしても破綻しない」状態を実現

**時間発展との関係:**

- 安定した空間の上でなら、「少しずつ変化する」プロセスを追跡できる
- 不安定な空間では、1ステップごとに予測不可能な変動が起きてしまう
