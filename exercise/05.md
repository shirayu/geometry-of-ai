# 第5回：分類の再統一 II

## 問題 5-1 ★ ArcFaceの角度マージン

ArcFaceの損失関数で、角度マージンm = 0.5ラジアン（約28.6度）を設けることの直感的意味を説明せよ。

**ヒント:** 同じクラス内の点は、クラス中心からどれだけ「余裕を持って」近くなければならないか？

**解答:**
**直感的意味:** 「正解クラスと判定されるためには、単に最も近いだけでは不十分。他のクラスより28.6度以上近くなければならない」

**具体例:**

- 入力xとクラス1の重心w₁の角度が30°
- 入力xとクラス2の重心w₂の角度が35°
- 通常のSoftmax：クラス1が選ばれる（30° < 35°）
- ArcFace (m=28.6°)：クラス1のスコアは cos(30°+28.6°) = cos(58.6°)、クラス2は cos(35°)
    - cos(58.6°) ≈ 0.52, cos(35°) ≈ 0.82 → クラス2が選ばれる！

**効果:** 学習時に「もっとクラス中心に近づけ」という強い圧力がかかり、クラス内の分散が小さくなる。結果として、クラス間の分離が良くなる。

## 問題 5-2 ★★ SVMとArcFaceのマージン

「SVMの最大マージン」と「ArcFaceの角度マージン」は、どちらも「マージン」という言葉を使うが、最適化問題として同一ではない。違いを説明せよ。

**ヒント:** SVMは何を「最大化」し、ArcFaceは何を「最小化」するか？

**解答:**
**SVM:**

- 目標：決定境界からサポートベクトルまでの距離（マージン）を最大化
- 制約：すべての点が正しく分類される
- 最適化：制約付き凸最適化問題（ラグランジュ双対など）
- マージンは「結果」として得られる

**ArcFace:**

- 目標：クロスエントロピー損失を最小化
- 角度マージンmは「ハイパーパラメータ」として事前に固定
- 最適化：通常の勾配降下
- マージンは「設計で決めるもの」であり、最適化の対象ではない

**違いの本質:** SVMは「最適なマージンを見つける」、ArcFaceは「決めたマージンを満たすように学習させる」。後者はニューラルネットの枠組みに自然に組み込める。
